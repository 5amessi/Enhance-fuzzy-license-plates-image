{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kAuteEA1Jox3","colab_type":"code","outputId":"b46e3a7d-dd95-4dd7-d29e-44edc490094e","executionInfo":{"status":"ok","timestamp":1557024346661,"user_tz":-120,"elapsed":5599,"user":{"displayName":"Mohamed Khamis","photoUrl":"https://lh3.googleusercontent.com/-Jn7z57ibgqA/AAAAAAAAAAI/AAAAAAAAAl4/Px3MbmkWgsU/s64/photo.jpg","userId":"04365449340744413916"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["! git clone https://github.com/5amessi/license_plates.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'license_plates'...\n","remote: Enumerating objects: 6, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 141 (delta 1), reused 0 (delta 0), pack-reused 135\u001b[K\n","Receiving objects: 100% (141/141), 24.37 MiB | 25.63 MiB/s, done.\n","Resolving deltas: 100% (10/10), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YrpWbgyEJqyE","colab_type":"code","outputId":"737a20f2-8528-4a3c-bc21-a4b3cb045739","executionInfo":{"status":"ok","timestamp":1557024352473,"user_tz":-120,"elapsed":10746,"user":{"displayName":"Mohamed Khamis","photoUrl":"https://lh3.googleusercontent.com/-Jn7z57ibgqA/AAAAAAAAAAI/AAAAAAAAAl4/Px3MbmkWgsU/s64/photo.jpg","userId":"04365449340744413916"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["! git clone https://github.com/SeyedHamidreza/car_plate_dataset.git\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'car_plate_dataset'...\n","remote: Enumerating objects: 48, done.\u001b[K\n","remote: Total 48 (delta 0), reused 0 (delta 0), pack-reused 48\n","Unpacking objects: 100% (48/48), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XYhX8sZRSobm","colab_type":"code","outputId":"974c8db9-3467-4d68-e35c-3e5be8aebae0","executionInfo":{"status":"ok","timestamp":1557024420093,"user_tz":-120,"elapsed":77117,"user":{"displayName":"Mohamed Khamis","photoUrl":"https://lh3.googleusercontent.com/-Jn7z57ibgqA/AAAAAAAAAAI/AAAAAAAAAl4/Px3MbmkWgsU/s64/photo.jpg","userId":"04365449340744413916"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TQVdBWI9Jq00","colab_type":"code","colab":{}},"source":["import zipfile\n","zip_ref = zipfile.ZipFile(\"/content/car_plate_dataset/IRCP_dataset_1024X768.zip\", 'r')\n","zip_ref.extractall(\"\")\n","zip_ref.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FM12IfNzJq3Z","colab_type":"code","outputId":"e99e2beb-35f3-4399-f44e-1a27d34be81d","executionInfo":{"status":"ok","timestamp":1557024429664,"user_tz":-120,"elapsed":10150,"user":{"displayName":"Mohamed Khamis","photoUrl":"https://lh3.googleusercontent.com/-Jn7z57ibgqA/AAAAAAAAAAI/AAAAAAAAAl4/Px3MbmkWgsU/s64/photo.jpg","userId":"04365449340744413916"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["import scipy\n","import cv2\n","from glob import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import keras\n","from keras.models import *\n","from keras.layers import *\n","\n","\n","class DataLoader():\n","    def __init__(self, dataset_name, img_res=(384, 192),out_res=(384, 192)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","        self.out_res = out_res\n","\n","    def load_data(self,png = False):\n","        if png == True:\n","          path = glob('/content/%s/*.png' % (self.dataset_name))\n","        else:\n","          path = glob('/content/%s/*' % (self.dataset_name))\n","        \n","        imgs_hr = []\n","        imgs_lr = []\n","\n","        \n","        for idx , i in enumerate(path):\n","          if idx >= 1000:\n","            break\n","          img = cv2.imread(i)\n","          w, h = self.img_res\n","          low_w, low_h = int(w / 3), int(h / 3)\n","\n","          img_hr = cv2.resize(img, self.out_res)\n","          \n","          img_lr = cv2.resize(img, (low_w, low_h))\n","          img_lr = cv2.resize(img_lr, self.img_res)\n","\n","          flr=np.fliplr(img_lr)\n","          fhr=np.fliplr(img_hr)\n","\n","          imgs_hr.append(img_hr)\n","          imgs_hr.append(fhr)\n","          imgs_lr.append(img_lr)\n","          imgs_lr.append(flr)    \n","\n","        imgs_hr = np.array(imgs_hr) / 127.5 - 1.\n","        imgs_lr = np.array(imgs_lr) / 127.5 - 1.\n","\n","        return imgs_hr, imgs_lr\n","\n","dl = DataLoader(\"license_plates\")\n","hr , lr = dl.load_data()\n","print(np.shape(hr))\n","print(np.shape(lr))\n","\n","dl = DataLoader(\"IRCP_dataset_1024X768\")\n","hr2 , lr2 = dl.load_data()\n","\n","print(np.shape(hr2))\n","print(np.shape(lr2))\n","hr = np.concatenate((hr, hr2))\n","lr = np.concatenate((lr, lr2))\n","hr2 = []\n","lr2 = []\n","print(np.shape(hr))\n","print(np.shape(lr))\n","t1 = (hr[0] + 1) * 127.5\n","t1 = np.array(t1, dtype=np.uint8)\n","cv2.imwrite('hr.jpg',t1)\n","t1 = (lr[0] + 1) * 127.5\n","t1 = np.array(t1, dtype=np.uint8)\n","cv2.imwrite('lr.jpg',t1)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["(220, 192, 384, 3)\n","(220, 192, 384, 3)\n","(440, 192, 384, 3)\n","(440, 192, 384, 3)\n","(660, 192, 384, 3)\n","(660, 192, 384, 3)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"z6oa07nzKI_9","colab_type":"code","colab":{}},"source":["def load_image_test(img):\n","  imgs_lr = []\n","  w, h = 384, 192\n","\n","  img_lr = cv2.resize(img, (w,h))\n","  \n","  imgs_lr.append(img_lr)\n","  imgs_lr = np.array(imgs_lr) / 127.5 - 1.\n","\n","  return imgs_lr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RZZkSEHmS0vB","colab":{}},"source":["from keras.engine.saving import load_model\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n","from keras.layers.advanced_activations import PReLU, LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.applications import VGG19\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import datetime\n","import matplotlib.pyplot as plt\n","import sys\n","import numpy as np\n","import os\n","\n","class SRGAN():\n","    def __init__(self):\n","        self.channels = 3\n","        self.lr_height = 192                 \n","        self.lr_width = 384                 \n","        self.lr_shape = (self.lr_height, self.lr_width, self.channels)\n","        self.hr_height = self.lr_height  \n","        self.hr_width = self.lr_width    \n","        self.hr_shape = (self.hr_height, self.hr_width, self.channels)\n","\n","        # Number of residual blocks in the generator\n","        self.n_residual_blocks = 16\n","\n","        optimizer = Adam(0.0001)\n","        \"\"\"\n","        pre-trained VGG19 model to extract image features from the high resolution image \n","        and the generated high resolution images and minimize the mse between them\n","        \"\"\"\n","        self.vgg = self.build_vgg()\n","        self.vgg.trainable = False\n","        self.vgg.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        patch = int(self.hr_height / 2**4)\n","        self.disc_patch = (patch, patch*2, 1)\n","\n","        # Number of filters in the first layer of Gen and Disc\n","        self.gf = 64\n","        self.df = 32\n","\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        self.generator = self.build_generator()\n","\n","        img_hr = Input(shape=self.hr_shape)\n","        img_lr = Input(shape=self.lr_shape)\n","\n","        fake_hr = self.generator(img_lr)\n","\n","        fake_features = self.vgg(fake_hr)\n","\n","        self.discriminator.trainable = False\n","\n","        validity = self.discriminator(fake_hr)\n","\n","        self.combined = Model([img_lr, img_hr], [validity, fake_features] )\n","        self.combined.compile(loss=['binary_crossentropy', 'mse'],\n","                              loss_weights=[1e-3, 1],\n","                              optimizer=optimizer)\n","\n","    def build_vgg(self):\n","\n","        vgg = VGG19(weights=\"imagenet\")\n","        vgg.outputs = [vgg.layers[9].output]\n","\n","        img = Input(shape=self.hr_shape)\n","\n","        img_features = vgg(img)\n","\n","        return Model(img, img_features)\n","\n","    def build_generator(self):\n","\n","        def residual_block(layer_input, filters):\n","            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n","            d = BatchNormalization(momentum=0.5)(d)\n","            d = Activation('relu')(d)\n","            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n","            d = BatchNormalization(momentum=0.5)(d)\n","            d = Add()([d, layer_input])\n","            return d\n","\n","        img_lr = Input(shape=self.lr_shape)\n","\n","        c1 = Conv2D(self.gf, kernel_size=9, strides=1, padding='same')(img_lr)\n","        c1 = Activation('relu')(c1)\n","\n","        r = residual_block(c1, self.gf)\n","        for _ in range(self.n_residual_blocks - 1):\n","            r = residual_block(r, self.gf)\n","\n","        c2 = Conv2D(self.gf, kernel_size=3, strides=1, padding='same')(r)\n","        c2 = BatchNormalization(momentum=0.5)(c2)\n","        c2 = Add()([c2, c1])\n","\n","        gen_hr = Conv2D(self.channels, kernel_size=9, strides=1, padding='same', activation='tanh')(c2)\n","\n","        return Model(img_lr, gen_hr)\n","\n","    def build_discriminator(self):\n","\n","        def d_block(layer_input, filters, strides=1, bn=True):\n","            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if bn:\n","                d = BatchNormalization(momentum=0.5)(d)\n","            return d\n","\n","        d0 = Input(shape=self.hr_shape)\n","\n","        d1 = d_block(d0, self.df, bn=False)\n","        d1 = d_block(d1, self.df, strides=2)\n","        d1 = d_block(d1, self.df*2)\n","        d1 = d_block(d1, self.df*2, strides=2)\n","        d1 = d_block(d1, self.df*4)\n","        d1 = d_block(d1, self.df*4, strides=2)\n","        d1 = d_block(d1, self.df*8)\n","        d1 = d_block(d1, self.df*8, strides=2)\n","\n","        d1 = Dense(self.df*8)(d1)\n","       \n","        d1 = LeakyReLU(alpha=0.2)(d1)\n","        validity = Dense(1, activation='sigmoid')(d1)\n","\n","        return Model(d0, validity)\n","    def pred(self ,count = 0,idx = 0):\n","        test = cv2.imread(\"/content/test.jpg\")\n","        test = load_image_test(test)\n","        result = self.generator.predict(test)\n","        result = (result + 1) * 127.5\n","        result = np.array(result, dtype=np.uint8)\n","        cv2.imwrite(\"testout%d.jpg\"%(count),result[0])\n","\n","        result = self.generator.predict([[lr[idx]]])\n","        result = (result + 1) * 127.5\n","        result = np.array(result, dtype=np.uint8)\n","        cv2.imwrite(\"output%d.jpg\"%(count),result[0])\n","\n","        result = (lr[idx] + 1) * 127.5\n","        result = np.array(result, dtype=np.uint8)\n","        cv2.imwrite(\"input%d.jpg\"%(count),result)\n","\n","    def train(self, gw, dw, gepochs, depochs, batch_size =4,saved=False):\n","        \n","        if saved == True:\n","          self.generator.load_weights(gw)\n","          self.discriminator.load_weights(dw)\n","\n","        #  Train Discriminator\n","        fake_hr = self.generator.predict(lr)\n","\n","        valid = np.ones((np.shape(hr)[0],) + self.disc_patch)\n","        fake = np.zeros((np.shape(hr)[0],) + self.disc_patch)\n","        \n","        print(\"Train the discriminators\")\n","        # Train the discriminators (original images = real / generated = Fake)\n","        self.discriminator.fit(hr, valid,verbose=1,batch_size=batch_size,epochs=depochs)\n","        self.discriminator.fit(fake_hr, fake,verbose=1,batch_size=batch_size,epochs=depochs*2)\n","\n","        #  Train Generator\n","\n","        # Extract features from hr image using pre-trained VGG19 model\n","        image_features = self.vgg.predict(hr)\n","\n","        print(\"Train the generators\")\n","        g_loss = self.combined.fit([lr, hr], [valid, image_features],verbose=1,batch_size=batch_size,epochs=gepochs)\n","        self.generator.save_weights(\"gdrive/My Drive/Colab Notebooks/generator.h5\")\n","        self.discriminator.save_weights(\"gdrive/My Drive/Colab Notebooks/discriminator.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mdqUkIezJq81","colab_type":"code","colab":{}},"source":["gan = SRGAN()\n","gan.train(_,_,gepochs=50,depochs=10,batch_size=4)\n","gan.pred(0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCjMeKYvDpZA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"8d429f3f-1b16-4691-9073-c70bf2995107","executionInfo":{"status":"ok","timestamp":1557024473535,"user_tz":-120,"elapsed":25493,"user":{"displayName":"Mohamed Khamis","photoUrl":"https://lh3.googleusercontent.com/-Jn7z57ibgqA/AAAAAAAAAAI/AAAAAAAAAl4/Px3MbmkWgsU/s64/photo.jpg","userId":"04365449340744413916"}}},"source":["gan = SRGAN()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n","574717952/574710816 [==============================] - 12s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TtVtOaJCntDa","colab_type":"code","colab":{}},"source":["gw = \"/content/gdrive/My Drive/Colab Notebooks/generator.h5\"\n","dw = \"/content/gdrive/My Drive/Colab Notebooks/discriminator.h5\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"07Nw0Zv1Dsxs","colab_type":"code","colab":{}},"source":["gan.train(gw,dw,gepochs=50,depochs=5,batch_size=4,saved=True)\n","gan.pred(1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Km5uu2fJm-MB","colab_type":"code","colab":{}},"source":["gan.train(gw,dw,gepochs=50,depochs=20,batch_size=4,saved=True)\n","gan.pred(2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"31YYJ8zaHqC1","colab_type":"code","colab":{}},"source":["gan.train(gw,dw,gepochs=10,depochs=10,batch_size=4,saved=True)\n","gan.pred(3)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eB6UzpaoqTo-","colab_type":"code","outputId":"bc5e9d6a-b020-4324-9cce-af61a27e32e9","executionInfo":{"status":"error","timestamp":1557003898023,"user_tz":-120,"elapsed":44968,"user":{"displayName":"Mohamed Khamis","photoUrl":"https://lh3.googleusercontent.com/-Jn7z57ibgqA/AAAAAAAAAAI/AAAAAAAAAl4/Px3MbmkWgsU/s64/photo.jpg","userId":"04365449340744413916"}},"colab":{"base_uri":"https://localhost:8080/","height":2808}},"source":["gan.train(gw,dw,gepochs=50,depochs=10,batch_size=4,saved=True)\n","gan.pred(4)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train the discriminators\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","660/660 [==============================] - 9s 14ms/step - loss: 0.2352 - acc: 0.7552\n","Epoch 2/10\n","660/660 [==============================] - 6s 9ms/step - loss: 0.0031 - acc: 0.9974\n","Epoch 3/10\n","660/660 [==============================] - 6s 9ms/step - loss: 1.7764e-04 - acc: 0.9999\n","Epoch 4/10\n","660/660 [==============================] - 6s 9ms/step - loss: 9.8987e-05 - acc: 0.9999\n","Epoch 5/10\n","660/660 [==============================] - 6s 9ms/step - loss: 3.4023e-05 - acc: 1.0000\n","Epoch 6/10\n","660/660 [==============================] - 6s 9ms/step - loss: 3.9067e-05 - acc: 1.0000\n","Epoch 7/10\n","660/660 [==============================] - 6s 9ms/step - loss: 2.0625e-05 - acc: 1.0000\n","Epoch 8/10\n","660/660 [==============================] - 6s 9ms/step - loss: 1.4104e-05 - acc: 1.0000\n","Epoch 9/10\n","660/660 [==============================] - 6s 9ms/step - loss: 1.4802e-05 - acc: 1.0000\n","Epoch 10/10\n","660/660 [==============================] - 6s 9ms/step - loss: 1.3188e-05 - acc: 1.0000\n","Epoch 1/20\n","660/660 [==============================] - 5s 8ms/step - loss: 0.1497 - acc: 0.8459\n","Epoch 2/20\n","660/660 [==============================] - 5s 8ms/step - loss: 1.2427e-05 - acc: 1.0000\n","Epoch 3/20\n","660/660 [==============================] - 5s 8ms/step - loss: 7.8340e-06 - acc: 1.0000\n","Epoch 4/20\n","660/660 [==============================] - 6s 8ms/step - loss: 6.2343e-06 - acc: 1.0000\n","Epoch 5/20\n","660/660 [==============================] - 6s 8ms/step - loss: 4.2752e-06 - acc: 1.0000\n","Epoch 6/20\n","660/660 [==============================] - 5s 8ms/step - loss: 3.7863e-06 - acc: 1.0000\n","Epoch 7/20\n","660/660 [==============================] - 5s 8ms/step - loss: 1.0990e-05 - acc: 1.0000\n","Epoch 8/20\n","660/660 [==============================] - 5s 8ms/step - loss: 5.5684e-06 - acc: 1.0000\n","Epoch 9/20\n","660/660 [==============================] - 5s 8ms/step - loss: 3.3204e-06 - acc: 1.0000\n","Epoch 10/20\n","660/660 [==============================] - 5s 8ms/step - loss: 2.7661e-06 - acc: 1.0000\n","Epoch 11/20\n","660/660 [==============================] - 6s 8ms/step - loss: 2.2968e-06 - acc: 1.0000\n","Epoch 12/20\n","660/660 [==============================] - 6s 8ms/step - loss: 1.9226e-06 - acc: 1.0000\n","Epoch 13/20\n","660/660 [==============================] - 6s 8ms/step - loss: 1.4674e-06 - acc: 1.0000\n","Epoch 14/20\n","660/660 [==============================] - 6s 8ms/step - loss: 1.6996e-06 - acc: 1.0000\n","Epoch 15/20\n","660/660 [==============================] - 6s 8ms/step - loss: 1.2823e-06 - acc: 1.0000\n","Epoch 16/20\n","660/660 [==============================] - 5s 8ms/step - loss: 1.0633e-06 - acc: 1.0000\n","Epoch 17/20\n","660/660 [==============================] - 5s 8ms/step - loss: 9.2763e-07 - acc: 1.0000\n","Epoch 18/20\n","660/660 [==============================] - 5s 8ms/step - loss: 8.3372e-07 - acc: 1.0000\n","Epoch 19/20\n","660/660 [==============================] - 6s 8ms/step - loss: 1.0014e-06 - acc: 1.0000\n","Epoch 20/20\n","660/660 [==============================] - 5s 8ms/step - loss: 7.4546e-07 - acc: 1.0000\n","Train the generators\n","Epoch 1/50\n","660/660 [==============================] - 174s 263ms/step - loss: 7.7141 - model_2_loss: 9.1598 - model_1_loss: 7.7049\n","Epoch 2/50\n","660/660 [==============================] - 165s 250ms/step - loss: 6.3206 - model_2_loss: 9.1551 - model_1_loss: 6.3115\n","Epoch 3/50\n","660/660 [==============================] - 165s 250ms/step - loss: 5.3100 - model_2_loss: 9.2000 - model_1_loss: 5.3008\n","Epoch 4/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.8723 - model_2_loss: 9.1988 - model_1_loss: 4.8631\n","Epoch 5/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.6615 - model_2_loss: 9.2022 - model_1_loss: 4.6523\n","Epoch 6/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.9230 - model_2_loss: 9.1953 - model_1_loss: 4.9139\n","Epoch 7/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.7167 - model_2_loss: 9.1576 - model_1_loss: 4.7075\n","Epoch 8/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.4672 - model_2_loss: 9.2476 - model_1_loss: 4.4579\n","Epoch 9/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.3791 - model_2_loss: 9.2343 - model_1_loss: 4.3698\n","Epoch 10/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.3359 - model_2_loss: 9.2782 - model_1_loss: 4.3266\n","Epoch 11/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.3430 - model_2_loss: 9.2281 - model_1_loss: 4.3337\n","Epoch 12/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.3150 - model_2_loss: 9.2354 - model_1_loss: 4.3057\n","Epoch 13/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.2988 - model_2_loss: 9.2128 - model_1_loss: 4.2896\n","Epoch 14/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.2444 - model_2_loss: 9.2280 - model_1_loss: 4.2352\n","Epoch 15/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.2765 - model_2_loss: 9.2571 - model_1_loss: 4.2673\n","Epoch 16/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.2059 - model_2_loss: 9.1965 - model_1_loss: 4.1967\n","Epoch 17/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.2473 - model_2_loss: 9.2230 - model_1_loss: 4.2380\n","Epoch 18/50\n","660/660 [==============================] - 165s 251ms/step - loss: 4.2206 - model_2_loss: 9.2253 - model_1_loss: 4.2113\n","Epoch 19/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.2024 - model_2_loss: 9.2835 - model_1_loss: 4.1931\n","Epoch 20/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.1711 - model_2_loss: 9.2247 - model_1_loss: 4.1619\n","Epoch 21/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.1858 - model_2_loss: 9.1891 - model_1_loss: 4.1766\n","Epoch 22/50\n","660/660 [==============================] - 165s 250ms/step - loss: 5.6648 - model_2_loss: 9.1987 - model_1_loss: 5.6556\n","Epoch 23/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.6681 - model_2_loss: 9.1693 - model_1_loss: 4.6589\n","Epoch 24/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.2137 - model_2_loss: 9.2125 - model_1_loss: 4.2045\n","Epoch 25/50\n","660/660 [==============================] - 165s 251ms/step - loss: 4.1480 - model_2_loss: 9.1971 - model_1_loss: 4.1388\n","Epoch 26/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.1178 - model_2_loss: 9.2562 - model_1_loss: 4.1086\n","Epoch 27/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.0908 - model_2_loss: 9.2157 - model_1_loss: 4.0816\n","Epoch 28/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.0679 - model_2_loss: 9.2304 - model_1_loss: 4.0587\n","Epoch 29/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.1077 - model_2_loss: 9.2717 - model_1_loss: 4.0984\n","Epoch 30/50\n","660/660 [==============================] - 165s 251ms/step - loss: 4.0986 - model_2_loss: 9.2495 - model_1_loss: 4.0893\n","Epoch 31/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.0980 - model_2_loss: 9.2152 - model_1_loss: 4.0888\n","Epoch 32/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.0382 - model_2_loss: 9.2526 - model_1_loss: 4.0290\n","Epoch 33/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.0333 - model_2_loss: 9.2036 - model_1_loss: 4.0241\n","Epoch 34/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.0558 - model_2_loss: 9.2162 - model_1_loss: 4.0466\n","Epoch 35/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.0041 - model_2_loss: 9.2168 - model_1_loss: 3.9949\n","Epoch 36/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.0204 - model_2_loss: 9.2469 - model_1_loss: 4.0112\n","Epoch 37/50\n","660/660 [==============================] - 165s 250ms/step - loss: 4.0338 - model_2_loss: 9.2091 - model_1_loss: 4.0246\n","Epoch 38/50\n","660/660 [==============================] - 165s 250ms/step - loss: 3.9848 - model_2_loss: 9.2302 - model_1_loss: 3.9755\n","Epoch 39/50\n","660/660 [==============================] - 165s 250ms/step - loss: 3.9698 - model_2_loss: 9.2074 - model_1_loss: 3.9606\n","Epoch 40/50\n","660/660 [==============================] - 165s 251ms/step - loss: 3.9406 - model_2_loss: 9.2287 - model_1_loss: 3.9314\n","Epoch 41/50\n","660/660 [==============================] - 165s 250ms/step - loss: 3.9411 - model_2_loss: 9.2646 - model_1_loss: 3.9319\n","Epoch 42/50\n","660/660 [==============================] - 165s 250ms/step - loss: 3.9196 - model_2_loss: 9.1924 - model_1_loss: 3.9104\n","Epoch 43/50\n","660/660 [==============================] - 165s 250ms/step - loss: 3.9611 - model_2_loss: 9.1819 - model_1_loss: 3.9519\n","Epoch 44/50\n","660/660 [==============================] - 165s 250ms/step - loss: 3.9599 - model_2_loss: 9.2641 - model_1_loss: 3.9506\n","Epoch 45/50\n","660/660 [==============================] - 165s 250ms/step - loss: 3.9525 - model_2_loss: 9.1977 - model_1_loss: 3.9433\n","Epoch 46/50\n","660/660 [==============================] - 165s 250ms/step - loss: 3.9271 - model_2_loss: 9.2026 - model_1_loss: 3.9179\n","Epoch 47/50\n","660/660 [==============================] - 165s 250ms/step - loss: 3.9242 - model_2_loss: 9.2209 - model_1_loss: 3.9149\n","Epoch 48/50\n","100/660 [===>..........................] - ETA: 2:20 - loss: 4.3001 - model_2_loss: 9.1319 - model_1_loss: 4.2910"],"name":"stdout"}]}]}